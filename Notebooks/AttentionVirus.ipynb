{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d264b48-63b5-4da5-94f3-e27b93b61020",
   "metadata": {
    "executionInfo": {
     "elapsed": 3883,
     "status": "ok",
     "timestamp": 1717144734523,
     "user": {
      "displayName": "Deep Amicizia",
      "userId": "02523504638128104887"
     },
     "user_tz": -120
    },
    "id": "f6a68b4e-8656-4dea-baf6-7fa911a9756c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69220931-dd1c-42b3-92d7-005a0aad2ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train path is set to: ../Dataset/fullset_train.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "train_path, validation_path, test_path = \"\", \"\", \"\"\n",
    "\n",
    "# Function to detect the environment\n",
    "def detect_environment():\n",
    "    # Check if Google Colab\n",
    "    try:\n",
    "        import google.colab\n",
    "        return 'colab'\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # Check if Jupyter Notebook\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return 'jupyter'\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return 'terminal'\n",
    "        else:\n",
    "            return 'other'\n",
    "    except NameError:\n",
    "        return 'other'\n",
    "\n",
    "# Set paths based on the detected environment\n",
    "env = detect_environment()\n",
    "\n",
    "if env == 'colab':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    train_path = \"/content/drive/MyDrive/fullset_train.csv\"\n",
    "    validation_path = \"/content/drive/MyDrive/fullset_validation.csv\"\n",
    "    test_path = \"/content/drive/MyDrive/fullset_test.csv\"\n",
    "elif env == 'jupyter':\n",
    "    train_path = \"../Dataset/fullset_train.csv\"\n",
    "    validation_path = \"../Dataset/fullset_validation.csv\"\n",
    "    test_path = \"../Dataset/fullset_test.csv\"\n",
    "else:\n",
    "    print(\"Unknown environment. Please set paths manually.\")\n",
    "\n",
    "# Use the DATA_PATH in your code\n",
    "if train_path:\n",
    "    print(f\"train path is set to: {train_path}\")\n",
    "else:\n",
    "    print(\"train_path is not set. Please check your environment settings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb4090f-91eb-430e-addc-d87f6ae67005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# device detection\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2e30f9d-cee2-40d1-9a10-ac4958aa347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "N_BASES = 4\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "n_epochs = 1\n",
    "\n",
    "threshold = 0.80\n",
    "\n",
    "loss_info_ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eed93ab-dbae-4d69-81b1-589d39f776a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU dataset version (immediately moves the data on GPU to enanche performaces)\n",
    "def convert_string_sequence_into_array(sequence):\n",
    "    \"\"\"Transforms a string into a numpy array of one-hot encoded data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence: str\n",
    "        input DNA sequence as string\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        the one-hot encoded DNA sequence as an array\n",
    "    \"\"\"\n",
    "    result = np.zeros(shape=(1, N_BASES, len(sequence)))\n",
    "    base_dict = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    for idx, base in enumerate(sequence.upper()):\n",
    "        result[0, base_dict[base], idx] = 1\n",
    "    return result\n",
    "\n",
    "class DNADatasetForGPU(Dataset):\n",
    "    \"\"\"Dataset built for performance\n",
    "    The previous versions used specific transformations, as shown in\n",
    "    https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html\n",
    "    but this massively slowed the computation time when we switched to the actual architecture\n",
    "\n",
    "    The actual dataset processes every tensor at \"first-reading time\", and moves it to the current device directly if needed.\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path):\n",
    "        df = pd.read_csv(csv_path, header=0, names=['seq_id', 'sequence', 'label'])\n",
    "\n",
    "        self.y = torch.tensor(df['label'].values).float().view(-1, 1).to(device)\n",
    "        self.x = torch.tensor(\n",
    "            np.array([convert_string_sequence_into_array(seq) for seq in df['sequence']])\n",
    "        ).float().to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d0b4e7-a4a4-4897-b4f6-20608765d8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211238 26404 26404\n",
      "fake_weight: 46.29914855957031\n",
      "fake_weight tensor size: torch.Size([1])\n",
      "general_weight: 0.021142030134797096\n",
      "general_weight tensor size: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# DATASET EXTRACTION\n",
    "train_dataset = DNADatasetForGPU(train_path)\n",
    "\n",
    "val_dataset = DNADatasetForGPU(validation_path)\n",
    "\n",
    "test_dataset = DNADatasetForGPU(test_path)\n",
    "\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
    "\n",
    "# calculating the ratio between the classes\n",
    "n_pos_examples = (train_dataset.y == 1).sum().item()\n",
    "n_neg_examples = len(train_dataset) - n_pos_examples\n",
    "\n",
    "fake_weight = n_neg_examples / float(n_pos_examples)\n",
    "general_weight = n_pos_examples / float(len(train_dataset))\n",
    "\n",
    "fake_weight_tensor = torch.tensor([fake_weight]).to(device)\n",
    "general_weight_tensor = torch.tensor([general_weight]).to(device)\n",
    "\n",
    "print(\"fake_weight:\", fake_weight_tensor.item())\n",
    "print(\"fake_weight tensor size:\", fake_weight_tensor.shape)\n",
    "print(\"general_weight:\", general_weight_tensor.item())\n",
    "print(\"general_weight tensor size:\", general_weight_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f40873c-8f84-4563-bd0f-afe12ba3695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_weight: 0.021142029369715674\n",
      "pos_weight: 0.9788579706302843\n",
      "Summation: 1.0\n"
     ]
    }
   ],
   "source": [
    "# testing that is a probability\n",
    "neg_weight = general_weight\n",
    "pos_weight = general_weight * fake_weight\n",
    "print(\"neg_weight:\", neg_weight)\n",
    "print(\"pos_weight:\", pos_weight)\n",
    "print(\"Summation:\", neg_weight + pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cf39fb3-3b91-4055-9442-a2ab223ca023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader declarations\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3328dc90-785b-4414-97a6-175587e3f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CHANNELS = 1\n",
    "SEQ_LENGTH = 300\n",
    "\n",
    "class AttentionVirusModel(nn.Module):\n",
    "    def __init__(self, blocks=6, embed_dim=128, L=2):\n",
    "        super(AttentionVirusModel, self).__init__()\n",
    "\n",
    "        self.pos_enc = PositionalEncoding(SEQ_LENGTH, L)\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(INPUT_CHANNELS, embed_dim, kernel_size=(4, 5)),\n",
    "            nn.BatchNorm2d(embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2))\n",
    "        )\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            *[SelfAttentionBlock(embed_dim, [148, embed_dim], embed_dim * 4) for i in range(blocks)]\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pos_enc(x)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # size [batch_size, self.maps, 1, 148] into [batch_size, 148, self.maps]\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()\n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "        \n",
    "        x = self.attention(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, seq_length, L):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        encoding = []\n",
    "        for exp in range(0, L):\n",
    "            sin_index = 2 * exp\n",
    "            cos_index = (2 * exp) + 1\n",
    "            encoding.insert(sin_index, [])\n",
    "            encoding.insert(cos_index, [])\n",
    "            omega = 2 ** exp\n",
    "            for position in range(0, seq_length):\n",
    "                enc_sin = np.sin(omega * np.pi * position)\n",
    "                encoding[sin_index].insert(position, enc_sin)\n",
    "                enc_cos = np.cos(omega * np.pi * position)\n",
    "                encoding[cos_index].insert(position, enc_cos)\n",
    "        self.pos_enc = torch.tensor(encoding, dtype=torch.float32).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x += self.pos_enc[:x.shape[1],:]\n",
    "        return x\n",
    "\n",
    "class SelfAttentionBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, norm_dim, linear_dim, heads=8):\n",
    "        super(SelfAttentionBlock, self).__init__()\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, heads, batch_first=True)\n",
    "        self.layer_norm1 = nn.LayerNorm(norm_dim)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(embed_dim, linear_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(linear_dim, embed_dim)\n",
    "        )\n",
    "        self.layer_norm2 = nn.LayerNorm(norm_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        att, _ = self.attention(x, x, x)\n",
    "        x = self.layer_norm1(x + att)\n",
    "        x = self.layer_norm2(x + self.linear(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed29ae26-4390-478d-947c-886abc9515c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionVirusModel(\n",
       "  (pos_enc): PositionalEncoding()\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 128, kernel_size=(4, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (attention): Sequential(\n",
       "    (0): SelfAttentionBlock(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (layer_norm1): LayerNorm((148, 128), eps=1e-05, elementwise_affine=True)\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (layer_norm2): LayerNorm((148, 128), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): SelfAttentionBlock(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (layer_norm1): LayerNorm((148, 128), eps=1e-05, elementwise_affine=True)\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (layer_norm2): LayerNorm((148, 128), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): SelfAttentionBlock(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (layer_norm1): LayerNorm((148, 128), eps=1e-05, elementwise_affine=True)\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (layer_norm2): LayerNorm((148, 128), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): SelfAttentionBlock(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (layer_norm1): LayerNorm((148, 128), eps=1e-05, elementwise_affine=True)\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (layer_norm2): LayerNorm((148, 128), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): SelfAttentionBlock(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (layer_norm1): LayerNorm((148, 128), eps=1e-05, elementwise_affine=True)\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (layer_norm2): LayerNorm((148, 128), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): SelfAttentionBlock(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (layer_norm1): LayerNorm((148, 128), eps=1e-05, elementwise_affine=True)\n",
       "      (linear): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (layer_norm2): LayerNorm((148, 128), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL DECLARATION\n",
    "model = AttentionVirusModel().to(device)\n",
    "\n",
    "def init_weights(layer):\n",
    "    \"\"\"Initialize weights for the model\"\"\"\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2d89e25-8134-42b6-87e3-a33f9ba0e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer definition\n",
    "criterion = nn.BCEWithLogitsLoss(weight=general_weight_tensor, pos_weight=fake_weight_tensor)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=learning_rate, max_lr=learning_rate*100, mode='triangular2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39918a3c-2726-4475-95df-2be2328b5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops definition\n",
    "def train_loop(dataloader, model, criterion, optimizer, loss_list, iter_per_epoch, loss_info_step=0):\n",
    "    \"\"\"Train loop\n",
    "    Performs a single training epoch over the dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataloader: torch.utils.data.dataloader.DataLoader\n",
    "        dataloader for the current dataset (should be train)\n",
    "    model: torch.nn.Module\n",
    "        model to train\n",
    "    criterion: loss function of pytorch\n",
    "        loss function used\n",
    "    optimizer: torch.optim.Optimizer\n",
    "        algorithm that performs the parameters update\n",
    "    loss_list: list\n",
    "        here the function appends each value of the average loss computed each loss_info_step number of iterations (see below)\n",
    "    iter_per_epoch: positive int\n",
    "        number of iterations within one epoch\n",
    "    loss_info_step: positive int (less than iter_per_epochs), optional\n",
    "        specifies the number of iterations that must pass before appending a new loss value to loss_list. It also specifies the time interval between\n",
    "        the output printing. If set to 0, no output will be printed and no loss will be stored. (default is 0)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    partial_loss = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):        \n",
    "        # forward pass and loss computation\n",
    "        y_pred = model(X)[:, -1, :] # choose the last token for the prediction        \n",
    "        loss = criterion(y_pred, y)\n",
    "        partial_loss += loss.item()\n",
    "    \n",
    "        # backward pass and params update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if loss_info_step != 0 and (batch + 1) % loss_info_step == 0:\n",
    "            # register loss for the plot\n",
    "            avg_loss = partial_loss / float(loss_info_step)\n",
    "            loss_list.append(avg_loss)\n",
    "            partial_loss = 0\n",
    "            # NOT IMPLEMENTED IN THIS FILE!\n",
    "            #plot_grad_flow(model.named_parameters())\n",
    "\n",
    "            # print some infos\n",
    "            print(f\"Iteration {batch + 1}/{iter_per_epoch}: avg_loss = {avg_loss:.6f}\")\n",
    "\n",
    "def validation_loop(dataloader, model, criterion, loss_list, threshold=0.5, loss_info_step=0):\n",
    "    \"\"\"Evaluation loop\n",
    "    Performs a single validation/test epoch over the dataset (evaluates the performaces)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataloader: torch.utils.data.dataloader.DataLoader\n",
    "        dataloader for the current dataset (should be validation or test)\n",
    "    model: torch.nn.Module\n",
    "        model to evaluate\n",
    "    criterion: loss function of pytorch\n",
    "        loss function used\n",
    "    loss_list: list\n",
    "        here the function appends each value of the average loss computed each loss_info_step number of iterations (see below)\n",
    "    iter_per_epoch: positive int\n",
    "        number of iterations within one epoch\n",
    "    threshold: [0, 1] float, optional\n",
    "        threshold value (defualt is 0.5)\n",
    "    loss_info_step: positive int (less than iter_per_epochs), optional\n",
    "        specifies the number of iterations that must pass before appending a new loss value to loss_list. It also specifies the time interval between\n",
    "        the output printing. If set to 0, no output will be printed and no loss will be stored. (default is 0)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        a tuple containing all the predictions and all the labels respectively as numpy.ndarray\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    partial_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # forward pass and loss computation\n",
    "            y_pred = model(X)[:, -1, :] # choose the last token for the prediction \n",
    "            loss = criterion(y_pred, y)\n",
    "            total_loss += loss.item()\n",
    "            partial_loss += loss.item()\n",
    "\n",
    "            # class prediction\n",
    "            prob_pred = nn.functional.sigmoid(y_pred)\n",
    "            #class_pred = prob_pred > threshold\n",
    "\n",
    "            # reporting results\n",
    "            all_preds.extend(prob_pred.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "            if loss_info_step != 0 and (batch + 1) % loss_info_step == 0:\n",
    "                # register loss for the plot\n",
    "                avg_loss = partial_loss / float(loss_info_step)\n",
    "                loss_list.append(avg_loss)\n",
    "                partial_loss = 0\n",
    "\n",
    "    # compute metrics\n",
    "    all_preds = np.array(all_preds).flatten()\n",
    "    all_labels = np.array(all_labels).flatten()\n",
    "    pred_labels = (all_preds > threshold).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, pred_labels)\n",
    "    precision = precision_score(all_labels, pred_labels, zero_division=0.0)\n",
    "    recall = recall_score(all_labels, pred_labels, zero_division=0.0)\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}, Average Loss: {avg_loss:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    return all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ade5a225-383b-4054-b808-eef8d9459d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m     train_loop(train_dataloader, model, criterion, optimizer, train_loss_list, iter_per_epoch_train, loss_info_step\u001b[38;5;241m=\u001b[39mloss_info_step_train)\n\u001b[0;32m     16\u001b[0m     validation_loop(val_dataloader, model, criterion, val_loss_list, threshold\u001b[38;5;241m=\u001b[39mthreshold, loss_info_step\u001b[38;5;241m=\u001b[39mloss_info_step_val)\n\u001b[0;32m     18\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[18], line 31\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, criterion, optimizer, loss_list, iter_per_epoch, loss_info_step)\u001b[0m\n\u001b[0;32m     29\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(X)[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;66;03m# choose the last token for the prediction        \u001b[39;00m\n\u001b[0;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y)\n\u001b[1;32m---> 31\u001b[0m partial_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# backward pass and params update\u001b[39;00m\n\u001b[0;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### MAIN LOOP\n",
    "iter_per_epoch_train = math.ceil(len(train_dataset) / float(batch_size))\n",
    "iter_per_epoch_val = math.ceil(len(val_dataset) / float(batch_size))\n",
    "loss_info_step_train = math.floor(iter_per_epoch_train * loss_info_ratio)\n",
    "loss_info_step_val = math.floor(iter_per_epoch_val * loss_info_ratio)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch + 1} -------------\")\n",
    "    train_loop(train_dataloader, model, criterion, optimizer, train_loss_list, iter_per_epoch_train, loss_info_step=loss_info_step_train)\n",
    "    validation_loop(val_dataloader, model, criterion, val_loss_list, threshold=threshold, loss_info_step=loss_info_step_val)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    torch.save(model.state_dict(), '../Models/best_model_AttentionVirusModel.pth')\n",
    "    \"\"\"\n",
    "    if val_loss_list[-1] < best_val_loss:\n",
    "        best_val_loss = val_loss_list[-1]\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), '../Models/best_model_AttentionVirusModel.pth')\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
